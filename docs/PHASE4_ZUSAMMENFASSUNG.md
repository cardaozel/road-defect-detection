% Phase 4: German Abstract (Zusammenfassung) - LaTeX Ready Version
% Copy the content below into your Overleaf Zusammenfassung section

Die Qualität der Straßeninfrastruktur beeinflusst die öffentliche Sicherheit, die Mobilität und die langfristige wirtschaftliche Effizienz. Wenn Risse, Schlaglöcher und Oberflächenschäden unbemerkt bleiben, wachsen die Instandsetzungskosten und die Gefahrensituationen im Straßenverkehr. Kommunale Stellen überwachen große Netze unter wechselnden Licht- und Wetterbedingungen, was eine zeitnahe Abdeckung erschwert. Computer Vision kann Teile dieser Aufgabe automatisieren, doch der Feldeinsatz bleibt durch Ressourcenbegrenzungen der Geräte und betriebliche Rahmenbedingungen eingeschränkt. Manuelle Begehungen sind weiterhin verbreitet, aber langsam, inkonsistent und schwer skalierbar. Viele automatisierte Ansätze setzen zudem Spezialhardware oder Cloud-Anbindung voraus, was die Nutzung im Außendienst erschwert. Daraus ergibt sich eine praktische Lücke: leichte On-Device-Systeme, die Erkennung und Meldung verbinden, werden benötigt.

Zur Schließung dieser Lücke schlägt die Arbeit eine On-Device-Pipeline zur Straßenschadenerkennung für die kommunale Meldung vor. Das Modell wird auf dem Road Damage Dataset 2022 (RDD2022) trainiert, mit 19.089 Trainingsbildern und 3.579 Validierungsbildern in sechs Defektklassen. Als Architektur wird YOLOv8s (You Only Look Once, kleine Variante) gewählt, um Genauigkeit und mobile Einschränkungen auszubalancieren. Das Training nutzt Transfer Learning mit COCO (Common Objects in Context)-Gewichten, einen 200-Epochen-Plan und Augmentationen wie Mosaic, Mixup und geometrische Transformationen zur Robustheitssteigerung. Das beste Checkpoint wird anhand der Validierungsmetriken ausgewählt und für iOS (Apple Mobile Operating System) nach CoreML (Core Machine Learning) exportiert. Eine native SwiftUI (Apple UI Framework)-App führt die Echtzeit-Inferenz aus, speichert die Detektionshistorie und verknüpft jede Erkennung mit GPS (Global Positioning System)-Koordinaten. Zusätzlich enthält die App ein Meldemodul mit Kontaktstellen für mehr als 25 Länder, sodass Meldungen direkt aus dem Feld erfolgen können.

Die Ergebnisse zeigen eine beste mittlere Average Precision (mAP)@0.5 von 49,19\%, mit einer Präzision von 60,43\% und einem Recall von 47,22\% auf dem Validierungssplit. Diese Leistung liegt über typischen Baseline-Bereichen für leichte Modelle und belegt die mobile Einsatzfähigkeit. Die CoreML-Konvertierung erhält das Modellverhalten und erzeugt ein bereitstellbares Paket für iOS-Geräte. Auf iPhone-12+-Hardware läuft die Inferenz in Echtzeit mit weniger als 50 ms pro Bild, was Live-Inspektion ermöglicht. Die Anwendung liefert sofortiges visuelles Feedback, strukturierte Defektzusammenfassungen und ortsbezogene Meldungen, wodurch Reibungsverluste in den Wartungsabläufen sinken. Die Kopplung von Erkennung und Meldung verbessert Reaktionszeiten und Dokumentationskonsistenz im kommunalen Betrieb.

Insgesamt liefert die Arbeit ein vollständiges On-Device-System zur Erkennung und Meldung, das für die praktische Straßeninstandhaltung geeignet ist. Es zeigt, dass ein kompaktes YOLOv8s-Modell feldtaugliche Genauigkeit erreicht und gleichzeitig eine umsetzbare Meldung über eine mobile Oberfläche ermöglicht.

\textbf{Schlagwörter:} Straßenschadenerkennung, Objekterkennung, YOLOv8, mobiles maschinelles Lernen, CoreML, On-Device-Inferenz, Infrastrukturmonitoring, kommunale Meldung
