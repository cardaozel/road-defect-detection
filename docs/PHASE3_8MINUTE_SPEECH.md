# Phase 3: 8-Minute Presentation Speech
**On-Device Road Damage Detection for Municipal Reporting**

---

## Slide 1: Title Slide (15 seconds)

"Good [morning/afternoon]. My name is Civan Arda Ã–zel, and I am presenting my thesis titled 'On-Device Road Damage Detection for Municipal Reporting' under the supervision of Prof. Dr. Iftikhar Ahmed and Prof. Dr. Raja Hashim Ali. This work was conducted from December 2025 to January 2026."

---

## Slide 2: Problem Statement (45 seconds)

"Let me start by explaining the problem we are addressing. Timely road maintenance is hindered by manual inspections that miss small but safety-critical defects such as cracks and potholes, especially under varying lighting conditions, different weather situations, and various camera angles.

The key challenges include: manual inspection limitations where inspectors miss small defects, inconsistent detection under varying conditions, and the time-consuming nature of manual inspections. Additionally, environmental variations like different lighting, weather conditions, and camera angles make detection difficult.

There is a clear need for a lightweight, reliable object detector that can run on commodity smartphones to localize common road surface defects in real time. This solution must be lightweight to run on standard smartphones, reliable across varying conditions, provide real-time feedback, and be accessible using commodity smartphones rather than specialized equipment."

---

## Slide 3: Research Questions (40 seconds)

"To address this problem, I formulated three research questions.

**Research Question 1** asks: What is the detection accuracy and performance of a YOLOv8-based model when trained on the RDD2022 dataset for road defect detection? This question investigates the achievable metrics like mAP, precision, and recall, and compares performance with baseline methods.

**Research Question 2** asks: Can a YOLOv8-based road defect detection model be successfully deployed on iOS mobile devices using CoreML while maintaining real-time inference performance? This examines the feasibility of CoreML conversion, real-time inference capabilities, and model size requirements.

**Research Question 3** asks: What are the usability characteristics and practical effectiveness of a mobile application for real-time road defect detection in field conditions? This evaluates the user interface design, real-time detection effectiveness, and practical applicability for field workers."

---

## Slide 4: Literature Review - Background & Methods (50 seconds)

"Now let me review the related work. For object detection methods, I focused on YOLO, which stands for 'You Only Look Once' - a real-time object detection framework. YOLOv8, released in 2023, is the latest version with improved accuracy and speed. Its advantages include single-stage detection, which is faster than two-stage methods, fast inference suitable for real-time applications, and a mobile-friendly architecture.

Previous road defect detection studies have focused on traditional computer vision methods with limited accuracy around 30-40%, or large-scale CNN models that are computationally expensive and not mobile-friendly. There has been limited research on mobile deployment for road defect detection, and most solutions require specialized equipment or cloud connectivity.

For mobile ML deployment, I used CoreML, which is Apple's framework for on-device machine learning. It enables real-time inference on iOS devices, utilizes the Neural Engine for optimized performance, and is privacy-preserving since no data leaves the device. The edge computing trend of moving inference to mobile devices offers benefits like privacy, low latency, offline capability, and reduced server costs."

---

## Slide 5: Related Work - Datasets & Benchmarks (45 seconds)

"For the dataset, I used the Road Damage Dataset 2022, or RDD2022, which is a multi-national road defect dataset. It contains 19,089 training images and 3,579 validation images, with 6 defect classes including longitudinal cracks, transverse cracks, alligator cracks, potholes, white line blur, and other defects. This is a standard benchmark for road defect detection research, collected from multiple countries including Japan, India, and the Czech Republic.

Looking at performance benchmarks, baseline models typically achieve 30-45% mAP@0.5, while state-of-the-art larger models achieve 60-70% mAP@0.5. However, there is a clear gap: we need mobile-deployable models with good accuracy above 45% mAP@0.5. The challenge is balancing model size for mobile deployment with accuracy for detection quality. Many recent studies use large CNN-based detectors that are computationally expensive and require powerful GPUs, limiting their practical deployment on mobile devices."

---

## Slide 6: Methodology (60 seconds)

"Now let me explain my methodology. For the dataset, I used the RDD2022 dataset with 19,089 training images and 3,579 validation images, covering 6 defect classes. The data was converted to YOLO format and preprocessing was applied, with data augmentation during training.

For the model architecture, I selected YOLOv8s, which is the Small variant. This model has 11 million parameters, making it a compact model optimized for mobile deployment. I selected it for the balance between accuracy and mobile compatibility. The model was pre-trained on the COCO dataset using transfer learning, then fine-tuned on the RDD2022 dataset. The image size is 640 by 640 pixels.

For the training strategy, I trained for 200 epochs with a cosine learning rate schedule. Data augmentation included mosaic augmentation, mixup augmentation, HSV color space augmentation, and rotation and scaling. The configuration was memory-optimized with a batch size of 4, zero workers for MPS device compatibility, and training on MPS, which is Metal Performance Shaders on macOS. The goal was to develop an efficient, mobile-deployable model achieving over 45% mAP@0.5 on RDD2022.

For mobile deployment, I converted the model to CoreML format for iOS compatibility, developed a native SwiftUI iOS application, implemented real-time camera inference using CoreML, added GPS location tagging for detected defects, and created a reporting system with location-based authorities for 25-plus countries."

---

## Slide 7: Results - Research Question 1 (70 seconds)

"Now let me present the results for Research Question 1. The training has completed 190 out of 200 epochs, which is 95% complete. The model started at 16.01% mAP@0.5 at Epoch 1, reached peak performance of 49.19% mAP@0.5 at Epoch 119, showing a 207% increase from start to best performance.

The best performance achieved includes: best mAP@0.5 of 49.19% at Epoch 119, best mAP@0.5:0.95 of 20.58% at Epoch 87, best precision of 60.82% at Epoch 120, and best recall of 47.22% at Epoch 152.

Comparing with benchmarks, the model exceeds baseline models which typically achieve 30-45% mAP@0.5, and is comparable to YOLOv8s expectations which are in the 45-55% mAP@0.5 range. We achieved strong results with a mobile-deployable model size, and the precision of 60.82% indicates a low false positive rate.

**To answer Research Question 1:** Yes, YOLOv8s demonstrates effective road defect detection on the RDD2022 dataset. We achieved 49.19% mAP@0.5, which is above baseline methods. The precision of 60.82% indicates a low false positive rate, and recall of 47.22% demonstrates good defect coverage. The 207% improvement from initial to best performance shows the model's learning capability. The performance is comparable to YOLOv8s expectations and exceeds baseline models."

---

## Slide 8: Results - Research Question 2 (60 seconds)

"Now for Research Question 2 regarding mobile deployment. The CoreML conversion was successful. The model format is compatible with iOS Neural Engine and optimized for on-device inference.

The model specifications include: a model size of approximately 43 megabytes in CoreML format, which is acceptable for mobile deployment. The inference time is less than 50 milliseconds on iPhone 12 and later models, optimized for the Neural Engine. Memory usage is optimized for mobile devices, and the format is CoreML dot mlmodel, compatible with iOS 14.0 and later.

For the iOS app implementation, I developed a native SwiftUI application with real-time camera inference integrated. The CoreML integration is complete and functional, with a user interface featuring bounding box visualization. Location services are integrated for GPS tagging, and there is a detection history management system. The reporting system supports 25-plus countries, with a comprehensive municipal contact database that includes phone numbers and email addresses for each road maintenance authority. The system automatically identifies the correct authority based on GPS coordinates and provides one-tap calling and email functionality for direct reporting.

**To answer Research Question 2:** Yes, the YOLOv8-based model can be successfully deployed on iOS mobile devices using CoreML with real-time inference performance. CoreML conversion was successful, real-time inference of less than 50 milliseconds per image is achieved, the model size of approximately 43 megabytes is acceptable, accuracy is preserved after CoreML conversion, and the complete iOS application with all features is implemented."

---

## Slide 9: Results - Research Question 3 (60 seconds)

"Now for Research Question 3 regarding usability and practical effectiveness. The iOS app features implemented include: real-time defect detection via camera, photo library import for batch processing, bounding box visualization with confidence scores, per-class color coding for 6 defect types, GPS location tagging for each detection, detection history management with thumbnails, and location-based reporting supporting 25-plus countries. The reporting system includes a comprehensive municipal contact database with phone numbers and email addresses for each road maintenance authority. The app automatically identifies the correct authority based on GPS coordinates and provides one-tap calling and email composition functionality, making it easy for users to directly contact the relevant municipal authority to report road defects.

The user interface features a modern SwiftUI design with intuitive navigation and user flow, clear visual feedback for detections, professional UI/UX with gradients and animations, and responsive and smooth interactions.

For practical utility, the app is field-ready - field workers can use it on-site with smartphones. It provides immediate feedback through real-time detection for instant road condition assessment. The reporting capability allows users to report issues directly from the app to maintenance authorities. It maintains a historical record of detections for tracking and analysis, and works offline without requiring an internet connection.

**To answer Research Question 3:** The mobile application demonstrates strong usability characteristics and practical effectiveness for real-time road defect detection in field conditions. The usability characteristics include an intuitive interface with modern SwiftUI design, real-time feedback with immediate detection results and visual bounding boxes, user-friendly features like photo import and history management, and professional design with polished UI/UX. The practical effectiveness includes: field-ready functionality that works on-site with standard smartphones, offline capability requiring no internet for detection, location integration with GPS tagging for precise defect reporting, a reporting system for direct reporting to authorities in 25-plus countries, and historical tracking that maintains detection records for analysis."

---

## Slide 10: Conclusion (50 seconds)

"To summarize, let me provide the answers to all three research questions.

**For Research Question 1:** Yes - YOLOv8s achieves 49.19% mAP@0.5 with 60.82% precision. This exceeds baseline methods and demonstrates effective road defect detection, with performance suitable for practical deployment.

**For Research Question 2:** Yes - The model was successfully deployed to iOS using CoreML. Real-time inference of less than 50 milliseconds is achieved, model size is acceptable, and the complete iOS application with all features is functional.

**For Research Question 3:** Yes - The application demonstrates strong usability and practical value. It features an intuitive interface, real-time detection, location tagging, and reporting capabilities, and is ready for field deployment and production use.

**The key contributions of this work include:** First, training a YOLOv8s model on the RDD2022 dataset, achieving 49.19% mAP@0.5 with 60.82% precision, using a mobile-optimized model with 11 million parameters. Second, successfully deploying to the iOS mobile platform with CoreML conversion completed, real-time inference achieved, and model size suitable for mobile deployment. Third, developing a complete iOS application with native SwiftUI, real-time detection and reporting capabilities, and professional UI/UX design.

**The impact of this work includes:** A practical solution for road maintenance and infrastructure monitoring, demonstrating the feasibility of mobile ML deployment for road defect detection, contributing to infrastructure monitoring technology with accessible tools, and enabling field workers to perform on-site defect detection.

This research delivers an end-to-end solution, from dataset to a deployment-ready iOS application. It exceeds baseline performance and sets the foundation for advanced mobile-centric road damage and infrastructure monitoring.

Thank you for your attention. I am now ready for questions."

---

## Timing Summary

- **Slide 1:** 15 seconds
- **Slide 2:** 45 seconds
- **Slide 3:** 40 seconds
- **Slide 4:** 50 seconds
- **Slide 5:** 45 seconds
- **Slide 6:** 60 seconds
- **Slide 7:** 70 seconds
- **Slide 8:** 60 seconds
- **Slide 9:** 60 seconds
- **Slide 10:** 50 seconds
- **Total:** ~8 minutes (495 seconds)

---

## Delivery Tips

1. **Pace yourself:** Speak clearly and at a moderate pace (~120 words per minute)
2. **Emphasize key numbers:** Stress important metrics (49.19%, 60.82%, <50ms, etc.)
3. **Pause between slides:** Brief pauses help the audience process information
4. **Eye contact:** Look at your audience, not just the slides
5. **Confidence:** You've done the work - speak with authority
6. **Practice:** Rehearse 2-3 times to get comfortable with timing

---

**Good luck with your presentation!**

