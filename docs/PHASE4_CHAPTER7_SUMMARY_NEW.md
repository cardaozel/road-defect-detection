% SUMMARY - Logic-corrected version (paste into Ch7)
% Mantık hataları düzeltildi:
% 1. robustness: "training data diversity rather than architectural novelty alone"
% 2. reformed → converted to CoreML and integrated into SwiftUI
% 3. small defects recollection → recall for small defects
% 4. not abandoning Windows → decision to keep Windows as a partial step
% 5. 49.19 0.5 mAP → 49.19\% mAP@0.5
% 6. Such a integration → Such an integration

The study began with a methodical search of available technologies applicable to object recognition, on-device inference, and their use in the fields, with a specification on the feasible solutions in a field setting \cite{edgeml2021}. Single-stage and two-stage detector comparisons were done, the comparison was made with the current families of detectors, and a trade-off between precision and the speed of inference was evaluated under the limitations of mobile execution \cite{terven2023}. The mobile inference choices were considered based on conversion support, runtime stability, and hardware acceleration as these were noted as predictors of real-time performance and long-term reliability on smartphones \cite{coreml2023}. Recent road damages data was studied in the context of realistic lighting, texture and variability of viewpoint and whether it is sufficiently realistic to capture the variety of situations that municipal inspectors have to deal with \cite{rdd2022,svrrd_2024}. Items highlighted in the analysis include the fact that to be able to detect effectively in uncontrolled settings, a compact model is needed, as well as a stable on-device runtime, rather than simply scoring high on the benchmarks. It also emphasized the lack of covered workflows to report on in the current literature, thus supporting the theme of municipal reporting and the need to bridge the gap between detection outputs and active processes \cite{smartcitysurvey2021}. Cracks versus lane markings: It has been observed that confusion between cracks and lane markings occurred in earlier studies, so the criteria used in the later analysis were influenced by that. Wet or shadowed surface sensitivity: It is known that cracks and lane markings are sensitive to wet or shadowed surfaces, and the later analysis criteria were based on this. Therefore, the range was reduced to methods that could work within strict mobile limitations without compromising reliability of deployment, which defined the limits within which all further decisions were made.

The critical methodological process included a step of filtering claims that seem to be strong in the literature but do not translate into being field-applicable. The reported accuracies were compared to model size, number of parameters, and inference latency of the models to get an understanding of the consistency with mobile requirements. Research based on heavy post processing or massive backbones were handled with care since they pose threat to real time use. Testing on non-homogenous surfaces was also of interest, not on purposely selected samples, since the field conditions are chaotic compared to the laboratory ones. These observations highlighted the fact that robustness is more strongly related to training data diversity rather than to architectural novelty alone. Uncorrelated labeling systems across datasets may lead to corrupt comparative analysis; the acknowledgment of that enhanced more critical interpretation of results and precluded misleading conclusions. Accordingly, the review struck a balance between technical performance and operational realism, which is required to deploy it in municipal service, and supported the requirement of a reporting pathway, as the sole trigger in maintenance action is actual detection. Such extensive scrutiny not only directed the thesis but also kept the researcher on course to avoid being subjected to unrealistic solutions.

After the review of technologies, three applicable services were chosen to be implemented basing on the factors of practicability and deployability. \gls{yolov8s} was selected based on its accuracy and speed, which is suitable to use on mobile devices without consuming too much energy \cite{yolov8}. The reason behind the adoption of \gls{coreml} is that it provides a consistent conversion path and utilizes the Apple Neural Engine to run it much faster without differing in the performance of \gls{ios}-based devices \cite{coreml2023,neuralengine2022}. \gls{swiftui} was chosen because it offers a clean and native workflow to inference on cameras, displaying the results, and taking action without any extra overhead of the frameworks \cite{swiftui2022}. Each of these choices was not based on convenience only but the necessity to make sure it is deployable to real devices, without delicate dependencies or complicated build instructions. These three pieces work together as the output of YOLOv8 can be used by \gls{coreml}, and \gls{swiftui} can use this model effectively to build a realistic and end-to-end system stack that is capable of being sustained over time. The selected architecture allows real-time inference and convenient reporting capabilities, therefore, fitting the goals of the thesis and bringing the research limitations into a specific engineering roadmap that can be implemented within the project scope.

The choice was also influenced by the factors of iteration speed when training and evaluating the training programs. The family model with strong tooling and full documentation was desirable in order to eliminate delays that were due to weak pipelines. The ability of \gls{coreml} to run identically on all \gls{ios} devices and hardware acceleration with no additional development of custom kernels was conclusive. The ability of \gls{swiftui} to minimise the complexity of glue-code to produce a consistent user interface proved useful especially in cases where there is a need to conduct continuous inference. This has been tested to be compatible with offline operation where field teams cannot always count on having a persistent network connection. These considerations led to an effective, supported and sustainable arrangement. The ruling also made life easier in terms of documentation to enable reproduction of the steps by other researchers who did not need specialised equipment. As a result, technical risk was prevented, creating a consistent base, on which the rest of the work was to be done, and promoting a consistent development as a result of ensuring that the feasibility and documentation are aligned.

Windows design and implementation plans were investigated in order to determine the compatibility of cross-platforms. A Windows workflow that was researched as a reflection of detection and reporting pipeline was prototyped, and a desktop interface was used to review the results and check the data quality in the initial experiments. Initial prototypes focused on dataset testing, visualizing of results and offline inference to test model behaviour in the non-mobile environment. The exploration clarified the noise of datasets and the ambiguity of classes, especially the thin cracks, patch boundaries, and low-contrast surfaces, and was used to make further augmentation plans. Although desktop inference may be used as a performance control and debugging tool, the findings did not change the overall design choices. Any attempt to develop it to production level as Windows did was not seen as a viable option, as cross-platform development would have watered down the implementation on mobile and slowed down the end-to-end process. The design notes will be used as a guide in case the scope is extended in the future, and they are explicitly documented, so that the scope is not an empty promise. The Windows exploration would therefore be a partial project which can be revisited should it be necessary to deploy the project across the platforms.

Although it was in limited form it provided useful checkpoints for data quality and model behaviour. The edge case, including bounding boxes close to lane markings or patch edges, could be inspected using desktop visualization tools that verified that some of the errors were as a result of the data and not the model. They were also useful in ensuring that the output formats and class mappings were verified before conversion. The experience revealed how much extra design would be required in a complete Windows client, with unique UI patterns and reporting processes that are not similar to mobile usage. Despite being valuable, this would have limited the time slot to be allocated on device testing and integration of reporting. To this effect, the decision to keep Windows as a partial step protected the core objective of the thesis and the work was clearly documented, clarifying the attempted work and its omission, thus, keeping the transparency and avoiding exaggerated claims.

The technical contribution consisted of the core element of the design of the system and the implementation on the mobile level so that all the parts of the pipeline would work in harmony with each other. It was trained on \gls{rdd2022}, converted to \gls{coreml}, and integrated into a \gls{swiftui} application that does inference on live camera frames \cite{rdd2022,coreml2023}. The training process took 200 epochs, which took about 8.8 hours, and used data augmentation and checkpoint selection to maximise accuracy without slowing down the speed \cite{yolov8}. A field-ready model was taken using the optimal checkpoint found at epoch 119 using validation performance. The application provides real-time detection overlays, confidence scores and historical view to enable both immediate action and the follow-up reporting. The workflow was introduced that the detected one could be linked to \gls{gps} coordinates and sent to the relevant authority, including pre-filled with the contact options \cite{geomobility2021}. This integration will change the system to a functional detector and a workable reporting tool to the field workers and a worthy prototype to be adopted by the municipals. Responsiveness could be tested by inference loop testing and the UI was well behaved when using continuous camera input without frame drops being visible. The mobile implementation, therefore, meets the thesis objective, which is detection, actionable reporting, and hardware-constraint compliance.

A careful effort was necessary to ensure that there were no discrepancies in output format and user interface expectation of a model. The coordinates of the bounding-box were checked to be correctly mapped on the view of the camera to ensure that overlay aligns with defects that are visible. The user interface was such that it would maintain the responsiveness of camera feeds and show detection labels in an unobtrusive way. The flow of the user verification led to the addition of a history screen and reviewing image process. The sustained inference was tested in terms of battery usage and thermal performance, as it is known that sustained inference can cause performance throttling. This emphasis on stability also guaranteed the usability of the application during realistic inspection, and the resultant system where the model, runtime and interface interact to each other in a natural manner as opposed to operating on its own. Such an integration is essential to practical implementation, which demonstrates that the project is not purely an academic project but can be used as a basis to do practical trials.

Documentation was also a key deliverable and not just a formality since it is understood that the utility of the system relies on the existence of reproducible steps. The structure of data sets, training settings, conversion pipeline, and integration with apps were recorded in detail, which allowed the reconstruction by the researchers later. Explicit hyperparameters, logic of selecting the checkpoints and data flow between training and deployment were defined. Output artefacts such as curves, confusion matrices and example detections were stored in a systematic manner which allows it to be verified and replicated. The documentation connects the empirical data to the physical files and scripts, which makes the evidences traceable and auditable, which is an essential feature in academic review that distinguishes assertions and assumptions and proves that each of the results can be reproduced. The municipal reporting feature was operationalized in terms of functionality to make it practically relevant to non-machine-learning stakeholders. This way, documentation can mediate between research and practice and improve the academic quality of the thesis at the same time increasing its impact in translation and facilitating additional development.

Besides narrative description, the tables and figures of raw data were strictly attributed to their origin. Excel-sheet tables were also used to record training hyperparameters, software stack, and evaluation metrics and thereby, audit thesis figures. The name of the files and the location of the files in the repository were maintained in a similar manner so that the next reader can easily understand. Such logical coherence plays a crucial role in a long thesis when various chapters have to mention the same artifacts. The design of the documentation is useful in a situation where a researcher wants to replicate the pipeline without any external explanation, and in a situation where the results need to be updated in case the model is retrained or extra data included. Documenting as a methodological element is more credible and less reliant on unproven narrative assertions, which increases transparency and is in line with academic standards. It also preconditions the possible open-source release of the project in case it should go beyond the limits of the thesis.

The assessment of the proposed solution was conducted using quantitative variables as well as pragmatic evaluation. The quality of detection was assessed with the help of \gls{map}, precision, and recall, and the visual inspection was used as a supplement to ensure that the bounding boxes that were predicted matched the visible defects \cite{zaidi2021}. The chosen checkpoint scored 49.19\% \gls{map}@0.5, which is a good score of a mobile-optimised model, but this score can still be improved without increasing model size. The analysis of errors showed the difficulties connected with thin cracks when under glare and low-contrast faults in shaded areas and the misunderstandings with lane markings. Live responsiveness of the application was also confirmed, which is an important requirement to deploy the application in the field and win the trust of the users. The reporting process was also put to test to ensure that detections were presently convertible into actionable reports within the app, and \gls{gps} tags are always captured. Thus, the assessment was not based on benchmark metrics and technical performance, but operational usability. This test concluded the research questions showing that the system is a deployable prototype. It also outlined the future working points, in particular, the enhancement of recall for small defects and brightness variability. These results provide an overview of definite areas of further development.

The analysis also put into perspective what enhancements would create maximum practical value not tied to incremental metric improvements. The slight improvement of \gls{map} is not of much use when it affects the real-time operation or makes the battery consumption in the field more troublesome. The precision versus recall was analyzed concerning the reporting workflows, whereby it was realised that false positives and missed defects do cost an operation. Visual checks were considered part of the process as it represents the interpretation of the field workers regarding the detections, in a way not represented by numeric measures. Stability on the types of defect was also evaluated to prevent reporting bias where small cracks and low-contrast defects were determined to be the most troublesome as was already known in literature. These lessons confirmed the move towards a lighter architecture that is more mobile-friendly at the expense of a heavier one. In this way, the analysis relates the technical outcomes to real-world limitations that encouraged the project and gives a clear explanation of the design decisions, which improves the thesis by equating metrics to usability and impact of operations.

These steps are systematic methodological processes that relate to the research questions. RQ1 (detection accuracy) is answered by training on \gls{rdd2022}, validation measurements, namely \gls{map}, precision and recall and checkpoint selection, which is described in Chapter~\ref{cha:chapter6}. The conversion pipeline, real-time verification of inference, and mobile implementation address RQ2 (deployment feasibility on \gls{ios} with \gls{coreml}). The reporting workflow, \gls{gps} tagging, detection history, and field-centred design are used to answer RQ3 (usability and practical effectiveness). Collectively, the steps will give the evidence necessary to provide responses to the research questions stated in Chapter~\ref{cha:chapter4}.
