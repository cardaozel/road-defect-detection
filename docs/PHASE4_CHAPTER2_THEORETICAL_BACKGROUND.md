% Phase 4: Chapter 2 - Theoretical Background - LaTeX Ready Version
% Copy the content below into your Overleaf Chapter 2 section

\chapter{Theoretical Background\label{cha:chapter2}}

This chapter provides the theoretical bases needed to understand the detection pipeline, mobile deployment limitations, and evaluation options used in this thesis. Over the last decade, object detection has gained traction and evolved from multi-stage pipelines to single, end-to-end formulations that focus on real-time performance \cite{zaidi2021,terven2023}. Road damage detection is a particular implementation that inherits the ideas of general detection but faces domain-specific difficulties, including texture variation, lighting shifts, and the small geometrical size of most defects \cite{yu2024}. The thesis focuses on an on-device strategy, which creates extra limitations on model size, latency, and energy use that are core to the edge machine learning literature \cite{edgeml2021}. The background information on model families and deployment technologies used in the following chapters requires a detailed overview, which is provided here \cite{terven2023,coreml2023}. Road damage datasets and detection benchmarks are also surveyed, with the main emphasis on \gls{rdd2022} as the primary data source \cite{rdd2022}. Lastly, the performance measurements used in this work are presented so that the comparison of training results, inference accuracy, and usability can be consistent \cite{zaidi2021}. This framing bridges the gap between theoretical decisions and the real-world goals of municipal reporting.

\section{Background}

Theoretical background for this thesis combines three intersecting areas: modern object detection, edge deployment, and road surface analysis. Object detection defines how to localize and classify multiple objects within an image, which is the core technical task of the system \cite{zaidi2021}. Recent detection models have shifted toward architectures that integrate feature extraction, localization, and classification into a single trainable pipeline \cite{terven2023}. Edge deployment introduces constraints that influence architecture choice and optimization strategies, because mobile devices have limited memory and energy budgets \cite{edgeml2021,mobiledets_2020}. Road surface analysis contributes application-specific context, including defect taxonomy and the visual appearance of cracks and potholes across diverse environments \cite{yu2024}. Together, these areas define the theoretical space where a practical, on-device road defect detector must operate. Figure~\ref{fig:ch2-detection-pipeline} presents a generic detection pipeline used to contextualize later design choices. The subsections below formalize key definitions, describe relevant detection families, and situate the dataset and deployment context used in this work. This layered background provides the rationale for why certain design compromises are necessary.

\begin{figure}[t]
    \centering
    \includegraphics[width=0.95\linewidth]{figures/figure_ch2_detection_pipeline.png}
    \caption{Generic object detection pipeline used across modern detectors.}
    \label{fig:ch2-detection-pipeline}
\end{figure}

\subsection{Definitions}

Object detection is the task of identifying object categories and estimating their bounding boxes within an image or video stream \cite{zaidi2021}. A detector produces class labels, confidence scores, and bounding box coordinates that localize each instance. On-device inference refers to executing the trained model directly on the target hardware, such as a smartphone, without offloading computation to the cloud \cite{edgeml2021}. Road defect detection is a specialized detection problem that targets surface anomalies like cracks, potholes, and blur lines, which are often thin, elongated, or low-contrast \cite{yu2024}. A dataset is a curated collection of labeled images used to train and evaluate the model, with \gls{rdd2022} serving as the primary benchmark in this thesis \cite{rdd2022,rdd2020_2021}. Model size refers to the storage footprint of the trained network, while latency denotes the time to process one image on the target device \cite{coreml2023}. Evaluation metrics such as precision, recall, and \gls{map} quantify detection quality across classes and thresholds \cite{zaidi2021}. These definitions establish the terminology that connects the theoretical discussion to the implementation in later chapters. They also clarify how performance claims are interpreted in a mobile context.





\begin{figure}[t]
    \centering
    \includegraphics[width=0.95\linewidth]{figures/figure_ch2_onestage_twostage.png}
    \caption{Comparison of two-stage and one-stage detection pipelines.}
    \label{fig:ch2-onestage-twostage}
\end{figure}

\begin{figure}[t]
    \centering
    \includegraphics[width=0.90\linewidth]{figures/figure_ch2_anchor_vs_anchorfree.png}
    \caption{Anchor-based versus anchor-free prediction concepts.}
    \label{fig:ch2-anchorfree}
\end{figure}

\subsection{Detection Model Families}

Modern object detectors are commonly organized into one-stage and two-stage families, with one-stage models favoring speed by predicting boxes and classes in a single pass \cite{zaidi2021}. \gls{yolo} variants are representative one-stage detectors that balance accuracy and real-time performance through dense prediction across feature maps \cite{terven2023,yolov7_2022}. Two-stage models first generate region proposals and then refine classification, which can improve accuracy but adds computational cost \cite{zaidi2021}. Recent detectors have also moved toward anchor-free prediction, which simplifies design by avoiding predefined anchor boxes and can improve adaptability to varying object shapes \cite{yolox2021}. Transformer-based detectors such as \gls{detr} reformulate detection as a set prediction problem and remove the need for \gls{nms}, which alters how post-processing is handled \cite{detr2020}. Efficient detectors such as EfficientDet focus on compound scaling and feature fusion to maintain strong accuracy under constrained resources \cite{efficientdet2020}. These families demonstrate the trade-offs between speed, accuracy, and complexity that must be considered for on-device road defect detection. Figure~\ref{fig:ch2-onestage-twostage} contrasts the execution flow of two-stage and one-stage detectors. Figure~\ref{fig:ch2-anchorfree} summarizes anchor-based versus anchor-free prediction. The thesis adopts a \gls{yolo} family model because its one-stage structure aligns with real-time constraints and established mobile deployment practices \cite{terven2023,rtmdet_2022}.

\begin{figure}[t]
    \centering
    \includegraphics[width=0.90\linewidth]{figures/figure_ch2_ondevice_stack.png}
    \caption{On-device inference stack used for iOS deployment.}
    \label{fig:ch2-ondevice-stack}
\end{figure}

\subsection{On-Device Deployment Constraints}

On-device deployment requires models to run strictly within constrained memory, computational and energy requirements as well as maintain a satisfactory degree of accuracy \cite{edgeml2021}. Mobile devices use special accelerators, such as the Apple Neural Engine, which perform inferences faster when the models are converted into an optimised format \cite{coreml2023}. \gls{coreml} is both the execution and the conversion system of \gls{ios}; thus, allowing effective and hardware-accelerated execution and on-device workflows of the deep-learning models \cite{coreml2023}. This, in turn, determines the choice of a model architecture based on a twofold need of accuracy of detections and compatibility with hardware, which encourages the use of small models, such as \gls{yolov8s}, over larger ones \cite{terven2023,yolov8}. Real-world implementation also requires regular preprocessing, fixed size inputs and deterministic latency to provide real time camera feeds. Edge inference has made its choices in favour of privacy and offline functionality, the data is kept within the device, which is particularly useful when using the technology in municipal field operations \cite{edgeml2021}. Figure~\ref{fig:ch2-ondevice-stack} shows the inference stack on device used in the deployment of \gls{ios}. These constraints have been theoretically understood and hence guide the model selection and optimisation processes described in the methodology chapter. In line with this, deployment considerations represent a non-nuanced requirement, and not a post processing consideration, of the system design. It is these limitations that then warrant the consideration of efficiency as a key measure that should be used with accuracy.

\begin{figure}[t]
    \centering
    \includegraphics[width=0.90\linewidth]{figures/figure_ch2_rdd2022_classes.png}
    \caption{\gls{rdd2022} defect classes used in this thesis.}
    \label{fig:ch2-rdd2022-classes}
\end{figure}

\subsection{Road Damage Data and Taxonomy}

The detection of road surface defects is influenced by a variation of surface texture, illumination and the small physical dimension of many of the manifestation of defects, thus making the data set quality of paramount importance \cite{yu2024}. The \gls{rdd2022} resource provides a consistent measure of six types of defects and coverage of locations functionally labeled across broad geographical areas and will help enable reproducible evaluation and comparison with antecedent investigations \cite{rdd2022,rdd2020_2021}. The data set includes longitudinal and transverse cracks, alligator cracks, pothole and other visual anomalies which possess variability in morphology and magnitude. Accurate localization of such categories of defects requires detectors that can delineate slender structures with irregular regions used in conjunction with them which represents a more challenging task compared to conventional object detection problems \cite{yu2024}. Moreover, road imagery is often contaminated with texture confounds, such as lane markings, patches in the surfaces of roads, shadows, and so on, which may spuriously generate false positives. An across theory understanding of dataset bias and sampling variability is undisputable for further interpretation of performance metrics \cite{rdd2022}. The defect categories are shown in Figure~\ref{fig:ch2-rdd2022-classes}. By framing the analysis in the context of a well-defined data set, this research to some extent insures comparability with more current research related to road damage. Consequently, this subsection forms the basis for this technical discourse in terms of the different visual and categorical features that are present in road damage data and highlights the need to carefully evaluate the methods used to avoid overstating the performance measures on comparatively easy cases \cite{yu2024}.

\section{Existing Methods}

Recent literatures on object detection describe a variety of architectures relevant to the road defect detection problem in which clear trade-offs exist between speed and accuracy. \gls{yolo}-based models dominate in the real-time domain by using a single-stage design for performing detection in one forward pass \cite{terven2023,yolov7_2022}. YOLOX included an anchor-free architecture and decoupled heads, to improve stability and accuracy without sacrificing speed, which has had an impact on the research of lightweight detectors \cite{yolox2021}. Transformer-based approaches like \gls{detr} have a completely different paradigm where the heuristic post-processing is replaced by set-based prediction and a global loss function \cite{detr2020}. EfficientDet focuses on resource efficient scaling using \gls{bifpn} feature fusion and so it boasts to be a solid reference point for mobile friendly detection \cite{efficientdet2020}. Comprehensive surveys are done to aggregate these families and compare their capability with the limitations of application, thereby providing the theoretical foundation for the choice of a compact version of \gls{yolo} \cite{zaidi2021}. In the case of road damage detection, as recent surveys emphasize the popularity of image bases of detectors and highlight the need to maintain high-performance under variable conditions of lighting and weather conditions \cite{yu2024}. The methodological review demonstrates that it is the most pragmatic solution to achieve real-time, on-device monitoring on the road, which is consistent with the imperative for consistent throughput on mobile devices \cite{terven2023}. The benchmark datasets have been used to detect road damage, especially, to facilitate comparisons and encourage the reproducibility of training pipelines \cite{rdd2022}. Empirical research on the problems of road surfaces shows that detectors need to have a sensitivity to fine-grained texture patterns and a resilience from the background clutter and motion blur \cite{yu2024}. Newer versions of \gls{yolo} such as \gls{yolov7} and \gls{yolov8} are cheaper in terms of both accuracy and speed and find wide usage in real-world detection applications \cite{yolov7_2022,yolov8}. Survey literatures also stress the fact that inference latency, memory footprint, and inference reliability in the field conditions, but not peak accuracy, are the important factors of successful deployment \cite{edgeml2021,zaidi2021}. In case of mobile inference, \gls{coreml} and on-device accelerator provides a runtime environment that can satisfy latency requirements without using the cloud \cite{coreml2023}. These collective considerations justify the use of a small \gls{yolov8s} model trained on \gls{rdd2022} for the thesis implementation, the choice is therefore anchored in both the advances in the algorithm and the operation of mobile road inspection. This overlap between the literature and application requirements is the basis for the methodology chapter, and also explains why the thesis focuses on reproducibility and evaluation on devices \cite{rdd2020_2021}.

\section{Evaluation Metrics}

\subsection{Localization and IoU}

The Intersection over Union (\gls{iou}) is the metric used to typically measure the quality of localization, and it is the degree of overlap between the predicted bounding boxes with their real-life counterparts, the ground-truths \cite{zaidi2021}. The \gls{iou} values range between [0,1] with high scores indicating high localization fidelity. When the \gls{iou} exceeds a predetermined threshold, a prediction is correct, and this threshold is usually 0.5 to assess the baseline \cite{terven2023}. With regard to small and long defects, like cracks, \gls{iou} is more susceptible to slight misalignments, hence, affecting the scores of detection even when the defect can be seen visually. In turn, the localization is a key indicator of the tasks of assessing road-damage, where the targets are flimsy and irregular \cite{yu2024}. Higher-level metrics of evaluation are obtained by setting the \gls{iou} thresholds, thus connecting localization accuracy to the general detection accuracy \cite{zaidi2021}. In the case of a real-time system, localization metrics further allow the interpretation of the fact that the gain in speed comes at the cost of spatial accuracy. In this respect, the basic quantification of geometrical accurateness used in the assessment is provided by \gls{iou}. It also explains the focus on bounding-box alignment in qualitative drawing \cite{zaidi2021}.

\subsection{Precision, Recall, and F1}

Precision and recall as quantitative measures of the accuracy and completeness of detections, respectively, are vital in explaining false alarms and defects that are missed, respectively \cite{zaidi2021}. Precision is a measure of the ratio of correctly predicted detections and recall is a measure of the ratio of ground-truth objects correctly detected. These measures depend on the chosen confidence threshold, which varies the trade-off between robustness and coverage \cite{terven2023}. The nature of road inspection requires a trade-off between accuracy and recall where a high number of false positives will result in losing user confidence and missing defects could lead to poor safety performance \cite{yu2024}. \gls{f1} combines both the precision and recall into a harmonic mean hence providing a succinct measure of reliability in detection. In mobile settings, thresholds can be optimized to put greater emphasis on larger accuracy in cases where field teams have the capacity to confirm detections \cite{edgeml2021}. Precision and recall in reporting allows the thesis to determine whether the performance has been limited due to false positives or missed defects. As a result, these measures play a critical role in the assessment of the practical usefulness in the real-world processes. In addition, they inform the choice of confidence levels to be used in the implemented application \cite{zaidi2021}.

\subsection{mAP and Runtime Metrics}

Mean Average Precision (\gls{map}) gives an overall overview of detection accuracy at a range of recall rates as well as Intersection over Union (\gls{iou}) rates, thus representing a generally agreed-upon metric on object-detection tasks \cite{zaidi2021}. The \gls{map}@0.5 metric is explicitly a metric that is used to evaluate performance at an \gls{iou} threshold of 0.5, but the \gls{map}@0.5:0.95 metric is a sum of performance at multiple thresholds, making it a more demanding metric of evaluation \cite{terven2023}. The inclusion of both metrics gives a fair view of both localization accuracy of coarse and fine-grained localization. In addition to accuracy, such operational metrics as inference latency and \gls{fps} are crucial to real-time applications \cite{edgeml2021}. A model with a large \gls{map} but unsuitable with real-time latency constraints is not suitable to mobile inspection processes. This thesis therefore considers the quality of detection along with the processing speed in order to fit within the real-life deployment setups \cite{coreml2023}. Figure~\ref{fig:ch2-metrics-flow} shows the trajectory of the computation of the metric between \gls{iou} and \gls{map}. It is an integrated method that makes it easy to conduct a strict evaluation of the trade-off between accuracy and efficiency. The metrics framework developed in this thesis is the basis of quantitative analysis of the results in the results chapter and provides a basis of system benchmarking with previous studies \cite{zaidi2021}.

\begin{figure}[t]
    \centering
    \includegraphics[width=0.90\linewidth]{figures/figure_ch2_metrics_flow.png}
    \caption{Evaluation metrics flow from \gls{iou} to \gls{map}.}
    \label{fig:ch2-metrics-flow}
\end{figure}
